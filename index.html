<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Chaosheng Dong</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Chaosheng Dong</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="paper.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Chaosheng Dong</h1>
</div>
<table class="imgtable"><tr><td>
<img src="chaosheng.jpg" alt="" width="150px" height="163px" />&nbsp;</td>
<td align="left"><p><a href="https://chaoshengdong.github.io">Chaosheng Dong</a>, Ph.D. <br />
Senior Applied Scientist <br />
Amazon <br /></p>
</td></tr></table>
<h2>Contact</h2>
<p>Email: <a href="mailto:chaosd@amazon.com">chaosd@amazon.com</a> <br />
Web: <a href="https://chaoshengdong.github.io">https://chaoshengdong.github.io</a> <br />
Google Scholar: <a href="https://scholar.google.com/citations?user=nPratvEAAAAJ&amp;hl=en">https://scholar.google.com/citations?user=nPratvEAAAAJ&amp;hl=en</a> <br />
<b>I am actively seeking journal review opportunities!</b>
<b>If you'd like to collaborate in research, please shoot an email!</b></p>
<h2>Recent News</h2>
<ul>
<li><p>Feb 22, 2025: Open source project <a href="https://github.com/amazon-science/MO-LightGBM">MO-LightGBM</a> is available at github.</p>
</li>
<li><p>Jan 22, 2025: Our paper <a href="https://openreview.net/pdf?id=MV28nFTVwM">AutoEval-ToD: Automated Evaluation of Task-oriented Dialog Systems</a> has been accepted by <b>NAACL 2025</b>.</p>
</li>
<li><p>Jan 22, 2025: Our paper <a href="https://arxiv.org/pdf/2405.15861">Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization</a> has been accepted by <b>ICLR 2025</b>.</p>
</li>
<li><p>Jan 20, 2025: Our paper <a href="https://arxiv.org/pdf/2310.09866.pdf">Generative Prompting for Complex Product Retrieval</a> has been accepted by <b>TheWebConf 2025</b>.</p>
</li>
<li><p>Mar 13, 2024: Our paper <a href="https://aclanthology.org/2024.findings-naacl.166.pdf">Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language Learning</a> has been accepted by <b>NAACL 2024</b>.</p>
</li>
<li><p>Jan 16, 2024: Our paper <a href="https://openreview.net/pdf?id=QcMdPYBwTu">Scalable and Effective Implicit Graph Neural Networks on Large Graphs</a> has been accepted by <b>ICLR 2024</b>.</p>
</li>
<li><p>Sep 21, 2023: Our paper <a href="https://arxiv.org/pdf/2310.09866.pdf">Federated Multi-Objective Learning</a> has been accepted by <b>NeurIPS 2023</b>.</p>
</li>
<li><p>Aug 5, 2023: Our paper <a href="https://arxiv.org/pdf/2306.14314.pdf">G-STO: Sequential Main Shopping Intention Detection via Graph-Regularized Stochastic Transformer</a> has been accepted by <b>CIKM 2023</b> as a long paper.</p>
</li>
<li><p>May 16, 2023: Our paper <a href="https://arxiv.org/pdf/2207.03060.pdf">Querywise Fair Learning to Rank through Multi-Objective Optimization</a> has been accepted by <b>KDD 2023</b> Research Track.</p>
</li>
<li><p>May 16, 2023: Our paper <a href="https://arxiv.org/pdf/2207.03060.pdf">Multi-Label Learning to Rank through Multi-Objective Optimization</a> has been accepted by <b>KDD 2023</b> Applied Data Science Track.</p>
</li>
<li><p>Jan 6, 2023: Our paper <a href="https://arxiv.org/pdf/2010.01687.pdf">Learning Risk Preferences from Investment Portfolios Using
Inverse Optimization</a> has been accepted by the special issue of AI and ML in Finance, Research in International Business and Finance.</p>
</li>
<li><p>Dec 27, 2022: Our paper <a href="https://www.amazon.science/publications/personalized-complementary-product-recommendation">Personalized Complementary Product Recommendation</a> was ranked <a href="https://www.amazon.science/latest-news/the-most-viewed-amazon-science-publications-of-2022">Top-10 most viewed publications of 2022</a> at Amazon.</p>
</li>
<li><p>July 7, 2022: Our paper <a href="https://arxiv.org/pdf/2207.03060.pdf">Multi-Label Learning to Rank through Multi-Objective Optimization</a> is available online.</p>
</li>
<li><p>May 15, 2022: Our paper <a href="https://assets.amazon.science/ff/1c/0be7a16c49a3aa8a3e6a93dd7b24/a-multi-objective-multi-task-learning-framework-induced-by-pareto-stationarity.pdf">A multi-objective / multi-task learning framework induced by Pareto stationarity</a> has been accepted by <b>ICML 2022</b>.</p>
</li>
<li><p>Mar 4, 2022: Our paper <a href="https://assets.amazon.science/50/06/5801f6eb43c6b688932c854b877a/multi-task-gnn-for-substitute-identification.pdf">Multi-task GNN for Substitute Identification</a> has been accepted by the Poster and Demo Track at the <b>the Web Conference 2022</b>.</p>
</li>
<li><p>Jan 29, 2022: Our paper <a href="https://www.amazon.science/publications/personalized-complementary-product-recommendation">Personalized Complementary Product Recommendation</a> has been accepted by the <b>the Web Conference 2022</b>.</p>
</li>
<li><p>Jan 20, 2022: Our paper <a href="https://openreview.net/pdf?id=Q83vFlie_Pr">Bandit Learning with Joint Effect of Incentivized Sampling, Delayed Sampling Feedback, and Self-Reinforcing User Preferences</a> has been accepted by <b>ICLR 2022</b>.</p>
</li>
<li><p>May 8, 2021: Our paper <a href="http://proceedings.mlr.press/v139/zhou21d/zhou21d.pdf">Incentivized Bandit Learning with Self-Reinforcing User Preferences</a> has been accepted by <b>ICML 2021</b>.</p>
</li>
<li><p>April 1, 2021: Our paper <a href="https://arxiv.org/abs/2104.13114">One Backward from Ten Forward, Subsampling for Large-Scale Deep Learning</a> has been accepted by the <a href="https://demalworkshop.github.io/">DeMaL Workshop</a> at WWW 2021.</p>
</li>
<li><p>Dec 10, 2020: Our paper <a href="https://www.amazon.science/publications/heterogeneous-graph-neural-networks-with-neighbor-sim-attention-mechanism-for-substitute-product-recommendation">Heterogeneous Graph Neural Networks with Neighbor-SIM Attention Mechanism for Substitute Product Recommendation</a> has been accepted by the <a href="https://deep-learning-graphs.bitbucket.io/dlg-aaai21/index.html">Workshop on Deep Learning on Graphs: Methods and Applications</a> at AAAI 2021.</p>
</li>
<li><p>Dec 1, 2020: Our paper <a href="https://arxiv.org/abs/2009.14552">Wasserstein Distributionally Robust Inverse Multiobjective Optimization</a> has been accepted by <b>AAAI 2021</b>.</p>
</li>
<li><p>Nov 08, 2020: Our paper <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/842-Paper.pdf">Expert Learning through Generalized Inverse Multiobjective Optimization: Models, Insights, and Algorithms</a> was selected as the <b>Runner-up</b> in the <b>best theoretical paper competition</b> in <a href="https://sites.google.com/view/dmdaworkshop2020/home">15th INFORMS Workshop on Data Mining &amp; Decision Analytics</a>.</p>
</li>
<li><p>Oct 13, 2020: Our paper <a href="https://arxiv.org/abs/2010.06140">Inverse Multiobjective Optimization Through Online Learning</a> is available online.</p>
</li>
<li><p>Oct 05, 2020: Our paper <a href="https://arxiv.org/abs/2010.01687">Learning Time Varying Risk Preferences from Investment Portfolios using Inverse Optimization with Applications on Mutual Funds</a> is available online.</p>
</li>
<li><p>Sep 30, 2020: Our paper <a href="https://arxiv.org/abs/2009.14552">Wasserstein Distributionally Robust Inverse Multiobjective Optimization</a> is available online.</p>
</li>
<li><p>May 31, 2020: Our paper <a href="http://proceedings.mlr.press/v119/dong20f/dong20f.pdf">Expert Learning through Generalized Inverse Multiobjective Optimization: Models, Insights and Algorithms</a> has been accepted by <b>ICML 2020</b>.</p>
</li>
<li><p>Dec 20, 2019: Chaosheng Dong will join <b>Amazon</b> as an Applied Scientist in machine learning starting from June 15, 2020.</p>
</li>
<li><p>Oct 19, 2019: Our paper <a href="https://papers.nips.cc/paper/7294-generalized-inverse-optimization-through-online-learning.pdf">Generalized Inverse Optimization through Online Learning</a> was selected as
one of the four Finalists in the best paper competition in <a href="https://sites.google.com/view/dmdaworkshop/home">14th INFORMS Workshop on Data Mining &amp; Decision Analytics</a>.</p>
</li>
<li><p>Oct 1, 2019: Our paper <a href="https://arxiv.org/pdf/1810.01920.pdf">Wasserstein Distributionally Robust Inverse Multiobjective Optimization</a> has been accepted by the <a href="https://sites.google.com/view/otml2019/home">OTML Workshop</a> at NeurIPS 2019.</p>
</li>
<li><p>Mar 7, 2019: Chaosheng Dong will join <b>ByteDance</b> as an Applied Machine Learning Intern starting from Sep 9, 2019.</p>
</li>
<li><p>Feb 18, 2019: Chaosheng Dong will join <b>Amazon</b> as an Applied Scientist Intern in machine learning starting from May 20, 2019.</p>
</li>
<li><p>Sep 5, 2018: Our paper <a href="https://arxiv.org/pdf/1810.01920.pdf">Generalized Inverse Optimization through Online Learning</a> has been accepted by <b>NIPS 2018</b>.</p>
</li>
</ul>
<h2>Education</h2>
<ul>
<li><p>Ph.D., Operations Research, <a href="https://www.pitt.edu/">University of Pittsburgh</a>, April 2020
</p>
</li>
<li><p>B.S.c., Mathematics and Applied Mathematics, <a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>, June 2014</p>
</li>
</ul>
<h2>Presentations and Activities</h2>
<ul>
<li><p><a href="https://demalworkshop.github.io/">DeMaL Workshop</a> at World Wide Web Conference (WWW 2021), April 2021</p>
</li>
<li><p>Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI 2021), February 2021</p>
</li>
<li><p><b>Best theoretical paper competition</b> in <a href="https://sites.google.com/view/dmdaworkshop2020/home">15th INFORMS Workshop on Data Mining &amp; Decision Analytics</a>, November 2020</p>
</li>
<li><p>Thirty-seventh International Conference on Machine Learning (ICML 2020), July 2020</p>
</li>
<li><p>OTML Workshop at NeurIPS 2019, Vancouver, Canada, December 2019</p>
</li>
<li><p><b>Session chair</b>, 2019 INFORMS Annual Meeting, Seattle, October 2019</p>
</li>
<li><p><b>Best theoretical paper competition</b> in <a href="https://sites.google.com/view/dmdaworkshop/home">14th INFORMS Workshop on Data Mining &amp; Decision Analytics</a>, October 2019</p>
</li>
<li><p>Jane Street Symposium, New York, January 2019</p>
</li>
<li><p>INFORMS Computing Society Conference, Knoxville, TN, January 2019</p>
</li>
<li><p>Thirty-second Conference on Neural Information Processing Systems (NeurIPS 2018), Montreal, Canada, December 2018</p>
</li>
<li><p>2018 INFORMS Annual Meeting, Phoenix, November 2018</p>
</li>
<li><p><b>University of Colorado Denver</b>, 2018 INFORMS Optimization Society Conference, March 2018</p>
</li>
<li><p>2017 INFORMS Annual Meeting, Houston, October 2017</p>
</li>
<li><p><b>UC Berkeley</b>, Optimization, Statistics and Uncertainty workshop, December 2017</p>
</li>
<li><p>2016 INFORMS Annual Meeting, Nashville, November 2016</p>
</li>
<li><p><b>IMA</b>, New Directions Workshop on Mathematical Optimization, August 2016</p>
</li>
<li><p><b>Autonomous University of Nuevo Leon</b>, 1st International Workshop on Bilevel Programming (IWOBIP&rsquo;16), Mexico, March 2016</p>
</li>
<li><p>2015 INFORMS Annual Meeting, Philadelphia, November 2015</p>
</li>
</ul>
<h2>Professional Services</h2>
<ul>
<li><p>Program Committee Member: KDD 2021 Research Track, SDM 2022, TheWebConf 2022  Industrial Track, KDD 2022 Research Track</p>
</li>
<li><p>Reviewer:  KDD 2021, AMLC 2021, NeurIPS 2021, ICLR 2022, TheWebConf 2022, ICML 2022, KDD 2022</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-02-26 03:17:50 PST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
